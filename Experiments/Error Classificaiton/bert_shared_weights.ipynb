{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "error.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f50f84340a064210acba40d1e76a0ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b591d317588d4eba9ee2b91065ce5818",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_631e291299d14cc9b2be93168cb5efc5",
              "IPY_MODEL_dbe1bab8f2f2479b9593dc340229e679"
            ]
          }
        },
        "b591d317588d4eba9ee2b91065ce5818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "631e291299d14cc9b2be93168cb5efc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7064efaf864548c8804c09a6b61c6515",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df75cfecb4b94364b1b36bb9bf2dd9a0"
          }
        },
        "dbe1bab8f2f2479b9593dc340229e679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa3b42a91dab4e148b7286b3125c7798",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 54.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d27274be05f7498898ddffac14a64a74"
          }
        },
        "7064efaf864548c8804c09a6b61c6515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df75cfecb4b94364b1b36bb9bf2dd9a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa3b42a91dab4e148b7286b3125c7798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d27274be05f7498898ddffac14a64a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01ae16ab60f941ceb37ea190155bf5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac743f4fb21042e294d93f4fb577557c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_84a91e0925e049d0ac04e700d7751905",
              "IPY_MODEL_4bbf59aba72d40458baf8fa79e4064d9"
            ]
          }
        },
        "ac743f4fb21042e294d93f4fb577557c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84a91e0925e049d0ac04e700d7751905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5221a967e8034f33b6c739554b7999c2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b67a5b728d147b5b02f940077ae584d"
          }
        },
        "4bbf59aba72d40458baf8fa79e4064d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6cc9ce8144443999268a147f2312249",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 71.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1755d89fd712463b8595e5878b9cce9e"
          }
        },
        "5221a967e8034f33b6c739554b7999c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b67a5b728d147b5b02f940077ae584d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6cc9ce8144443999268a147f2312249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1755d89fd712463b8595e5878b9cce9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d36079de2984fad9c160bca1b48fe98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a7c4fbd142745569ac1480db6661daa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_28cb707c913b4fc5b90b91970f8ea8c9",
              "IPY_MODEL_db3fa894a19047c997f3bf33987adda5"
            ]
          }
        },
        "1a7c4fbd142745569ac1480db6661daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28cb707c913b4fc5b90b91970f8ea8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c619123b55d74ae0a392634c7a757e2b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_001f239058aa4d859e7226a682fc65f0"
          }
        },
        "db3fa894a19047c997f3bf33987adda5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65cdfe2f55c04106bdb2cd5b1c1a6efb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.26MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbe66f41063144b0851119e536b87f6d"
          }
        },
        "c619123b55d74ae0a392634c7a757e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "001f239058aa4d859e7226a682fc65f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65cdfe2f55c04106bdb2cd5b1c1a6efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbe66f41063144b0851119e536b87f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFvFcJ18PcIf"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUZ2Yw0ePjsX"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm , trange\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from sklearn.metrics import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbPc9xrDVcrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1a3a53-7be1-442d-bb0a-aa41aca79d6a"
      },
      "source": [
        "import pandas as pd\n",
        "!git clone https://gitlab.com/vibss2397/nlp.git\n",
        "df = pd.read_csv(\"nlp/fce_final.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 35 (delta 12), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n",
            "Checking out files: 100% (7/7), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRC1IoeAxQhK"
      },
      "source": [
        "!ls nlp"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJhgyUJe3Yyw"
      },
      "source": [
        "# Old Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfeUtYlDC-BC"
      },
      "source": [
        "df1 = df[['incorrect', 'correct', 'start_off', 'end_off', 'err_type']]\n",
        "df1 = np.array(df1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBBBzJAML2MN"
      },
      "source": [
        "for i in range(227, 242):\n",
        "  df1[i][1] = 'In the twenty-first century, things are changing very fast. If we look at  family life, they have a lifestyle which is typical of these times. Children have their own televisions, computers and telephones in their room. Mother and Father have their own cars and mobile phones. Sometimes even the children have their own mobile phone as well. The house : fire alarm, burglar alarm, house temperature gauge, automatic garage door, etc. They use all of this because they want to do their work and leisure activities with these helping kits.' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggEIrJGBza1D"
      },
      "source": [
        "final = []\n",
        "for ele in df1:\n",
        "  if(type(ele[0])!=float and type(ele[1])!=float):\n",
        "    incorr = ele[0]\n",
        "    corr = ele[1]\n",
        "    # print(incorr+'\\n', corr)\n",
        "    corr = ele[1].split('. ')\n",
        "    corr = [ele for ele in corr if len(ele)>0]\n",
        "    corr = [ele if (ele[-1]=='.' or ele[-1]==',' or ele[-1]=='?' or ele[-1]=='!') else ele+'.' for ele in corr]\n",
        "    incorr_arr = []\n",
        "    \n",
        "    start_off = ele[2]\n",
        "    end_off = ele[3]\n",
        "    temp = ''\n",
        "    sent = 0\n",
        "    counter = 0\n",
        "    pos_start, pos_end = 0, 0\n",
        "    for line in corr:\n",
        "      last_word =  line.split(' ')[-1].strip('.').strip(',').strip('?') if len(line.split(' '))==1 else line.split(' ')[-2].strip('.').strip(',').strip('?')\n",
        "      # last_word_final = last_word if last_word.find('.')<0 else last_word[:-1]\n",
        "      incorr_find = incorr.find(last_word, pos_end)\n",
        "      pos_end = incorr_find + len(last_)\n",
        "      incorr_arr.append(incorr[pos_start:pos_end])\n",
        "      pos_start = pos_end + 2\n",
        "    final.append(tuple([incorr_arr, corr, start_off, end_off, ele[4]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTp2wAyQxSFT",
        "outputId": "c5bcc3fa-4e00-4b84-82c9-9290bd062818"
      },
      "source": [
        "# pd.DataFrame(final, columns =['incorr', 'corr', 'start_off', 'end_off', 'err'])\n",
        "final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['In the twenty first century things are changing very fast. ',\n",
              "   'If we look at a family life. They have typical  lifestyle  typical  these times. ',\n",
              "   'Children have  own televisions, computers and telephones in their room. ',\n",
              "   'Mother and Father have  own cars and mobile phones. ',\n",
              "   'Sometimes even the children have  own mobile phone as well. ',\n",
              "   '',\n",
              "   'he twenty first century things are changing very fast. If we look at a family life. They have typical  lifestyle  typical  these times. Children have  own televisions, computers and telephones in their room. Mother and Father have  own cars and mobile phones. Sometimes even the children have  own mobile phone as well. Full of technological tools and instruments . Fire alarm, burglar alarm, house temperature checker, automatic garage door many of them. They use all of this because they want to do their work, and leisure activities with this helping kits.'],\n",
              "  ['In the twenty-first century, things are changing very fast.',\n",
              "   'If we look at  family life, they have a lifestyle which is typical of these times.',\n",
              "   'Children have their own televisions, computers and telephones in their room.',\n",
              "   'Mother and Father have their own cars and mobile phones.',\n",
              "   'Sometimes even the children have their own mobile phone as well.',\n",
              "   'The house : fire alarm, burglar alarm, house temperature gauge, automatic garage door, etc.',\n",
              "   'They use all of this because they want to do their work and leisure activities with these helping kits.'],\n",
              "  154,\n",
              "  154,\n",
              "  'LX')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rro_-Zf20yzA",
        "outputId": "e69eeae2-e713-43e9-9782-5f44d949ac21"
      },
      "source": [
        "for tup in final[1:]:\n",
        "  incorr = tup[0]\n",
        "  corr = tup[1]\n",
        "  corr = [ele[:-1] if (ele[-1]=='.' or ele[-1]==',' or ele[-1]=='?' or ele[-1]=='!') else ele for ele in corr ]\n",
        "  start = 0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I have received your letter, which  makes me happy', 'For the first time in my life I have won a competition', 'I would like to take you up on your invitation in July', 'I am only able to take my holiday in July', 'The rest of the year I work']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6srXjGntrw_-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrMrHM3mLqo2",
        "outputId": "c60ea839-5bd1-4c88-dd23-e16a4a22db22"
      },
      "source": [
        "final[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['I have received your letter which is make me happy',\n",
              "  'The first time in my life I have won  competition',\n",
              "  'I would like to attempt your invite in July',\n",
              "  'I  only able to take my holidy in July,  rest of the year I work.'],\n",
              " ['I have received your letter, which  makes me happy',\n",
              "  'For the first time in my life I have won a competition',\n",
              "  'I would like to take you up on your invitation in July',\n",
              "  'I am only able to take my holiday in July',\n",
              "  'The rest of the year I work.'],\n",
              " 27,\n",
              " 27,\n",
              " 'OT')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Krsl-q_wvYT4",
        "outputId": "85edb454-66fe-4591-9baf-3176f14b7956"
      },
      "source": [
        "!ls nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'nlp': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Yf-uV6YqH9"
      },
      "source": [
        "df1 = df[['incorrect', 'err_type']]\n",
        "df1 = df1.rename(columns={'incorrect':'input','err_type':'err'})\n",
        "df2 = df[['correct']]\n",
        "# df2['err'] = 'CO'\n",
        "df2.insert(1, 'err', 'CO')\n",
        "df2 = df2.rename(columns={'correct':'input','err':'err'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzQy-6UJu_E3"
      },
      "source": [
        "frames = [df1, df2]\n",
        "result = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtwtA9pnZFuJ"
      },
      "source": [
        "df3 = result.groupby(by='input')['err'].unique().apply(lambda x: ','.join(x)).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5qF0myInmNC"
      },
      "source": [
        "df3['err'] = df3.err.str.split(',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mit0DPLIMnq"
      },
      "source": [
        "def remove_arr(arr, ele):\n",
        "  if ele in arr:\n",
        "    arr.remove(ele)\n",
        "  return arr\n",
        "\n",
        "df3['err'] = df3['err'].apply((lambda x: ['CO'] if 'CO' in x else x))\n",
        "df3['err'] = df3['err'].apply(lambda x: remove_arr(x, 'DS')).apply(lambda x: remove_arr(x, 'SM'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4udTU-phNXi1"
      },
      "source": [
        "df3_final = df3[df3['err'].apply(lambda x: len(x)!=0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CrWSrZXXRdd"
      },
      "source": [
        "err_categories = sorted(['LX', 'OT', 'GM', 'CO'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWJTP57CnxeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be5e632-a89c-4654-9f45-12a8b0de8940"
      },
      "source": [
        "for err_type in err_categories:\n",
        "  df3_final[err_type] = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJOITIOteyWg"
      },
      "source": [
        "def make_1(row):\n",
        "  for ele in row[1]:\n",
        "    row[2 + err_categories.index(ele)] = 1\n",
        "  return row\n",
        "df3_final = df3_final.apply(make_1, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtPH44zPkGfh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ab17dd34-57aa-41e8-a8ca-635d310044e9"
      },
      "source": [
        "df3_final.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>err</th>\n",
              "      <th>CO</th>\n",
              "      <th>GM</th>\n",
              "      <th>LX</th>\n",
              "      <th>OT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"She was very angry when I arrived. She stare...</td>\n",
              "      <td>[LX, GM, OT]</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"She was very angry when I arrived. She stare...</td>\n",
              "      <td>[CO]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100 years ago, people dressed   differently. ...</td>\n",
              "      <td>[CO]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1st \"F\" is from \"fast-food\", something fast a...</td>\n",
              "      <td>[LX, OT]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2nd F is 'fulfill' wear ever you have under y...</td>\n",
              "      <td>[LX, OT, GM]</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               input           err  ...  LX  OT\n",
              "0   \"She was very angry when I arrived. She stare...  [LX, GM, OT]  ...   1   1\n",
              "1   \"She was very angry when I arrived. She stare...          [CO]  ...   0   0\n",
              "2   100 years ago, people dressed   differently. ...          [CO]  ...   0   0\n",
              "3   1st \"F\" is from \"fast-food\", something fast a...      [LX, OT]  ...   1   1\n",
              "4   2nd F is 'fulfill' wear ever you have under y...  [LX, OT, GM]  ...   1   1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZH2m885kWsV"
      },
      "source": [
        "df4 = df3_final.drop('err', axis = 1)\n",
        "# df4.to_csv('processed_fce.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DObzwPOE3mKd"
      },
      "source": [
        "# New Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO_J92IXlVzp"
      },
      "source": [
        "df4 = pd.read_csv('nlp/fce_final.csv')\r\n",
        "df4.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMs0J7bN3tgi"
      },
      "source": [
        "#selecting sentence and labels\r\n",
        "df4 = df4[['0', '1']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yZ6G1ugmFTa"
      },
      "source": [
        "df4['len'] = df4.apply(lambda x: len(x[0].split('. ')), axis=1)\n",
        "df5 = df4[['input', 'len']]\n",
        "df5_numpy = df5.to_numpy()\n",
        "max_len = ['', float('-inf')]\n",
        "for ele in df5_numpy:\n",
        "  if(ele[1]>max_len[1]):\n",
        "    max_len[0] = ele[0]\n",
        "    max_len[1] = ele[1]\n",
        "df4 = df4.drop('len', axis=1)\n",
        "final_df = pd.concat([df4['input'], df4.apply(lambda x: np.array(x[1:], dtype=np.float), axis=1)], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKSnrzFVHIJt"
      },
      "source": [
        "max_len"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4y4ADEkHnOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf36dca-d811-42df-9965-90be087ad2e3"
      },
      "source": [
        "train_data = final_df.sample(frac=0.80, random_state=0)\n",
        "test_data = final_df.drop(train_data.index)\n",
        "train_data_arr = train_data.to_numpy()\n",
        "test_data_arr = test_data.to_numpy()\n",
        "\n",
        "print(\"Train shape\", train_data_arr.shape)\n",
        "print(\"Test shape\", test_data_arr.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape (14266, 2)\n",
            "Test shape (3567, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMpShc4zIW_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a8d0dedf-885e-44c5-a8e1-ac069017e605"
      },
      "source": [
        "train_data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16165</th>\n",
              "      <td>Unfortunately, Pat wasn't very good at keeping...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7256</th>\n",
              "      <td>I hope you will take my proposal into favourab...</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4397</th>\n",
              "      <td>Firstly, I must admit that when we realised th...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1053</th>\n",
              "      <td>Also the clothes in a hundred years will have ...</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17340</th>\n",
              "      <td>With your agreement we could change the progra...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   input                     0\n",
              "16165  Unfortunately, Pat wasn't very good at keeping...  [0.0, 0.0, 1.0, 0.0]\n",
              "7256   I hope you will take my proposal into favourab...  [1.0, 0.0, 0.0, 0.0]\n",
              "4397   Firstly, I must admit that when we realised th...  [0.0, 0.0, 1.0, 0.0]\n",
              "1053   Also the clothes in a hundred years will have ...  [1.0, 0.0, 0.0, 0.0]\n",
              "17340  With your agreement we could change the progra...  [0.0, 0.0, 1.0, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASLOHie84rHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a338dc-23d8-4449-c429-e83dde4fd541"
      },
      "source": [
        "weights = np.array(train_data[0].agg('sum'), dtype=np.float)\n",
        "weights_sum = np.sum(weights)\n",
        "weights2 = weights_sum/weights\n",
        "weights2 = weights2 / weights2[0]\n",
        "# weights2 = np.exp(weights2)/sum(np.exp(weights2))\n",
        "print(weights2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.         1.70293486 1.15317499 2.08136483]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDEYYpxpQuVC"
      },
      "source": [
        "# Final Training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3o7s9LkI0r-"
      },
      "source": [
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "          super(CustomBERTModel, self).__init__()\n",
        "          self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "          for name, param in self.bert.named_parameters():\n",
        "            param.requires_grad = True\n",
        "          # add your additional layers here, for example a dropout layer followed by a linear classification head\n",
        "          self.dropout = nn.Dropout(0.5)\n",
        "          self.out1 = nn.Linear(768, 4)\n",
        "          self.relu = nn.ReLU()\n",
        "          self.out2 = nn.Linear(256, 4)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
        "          bert_outputs = self.bert(\n",
        "               input_ids, \n",
        "               attention_mask,\n",
        "               token_type_ids\n",
        "          )\n",
        "          out1 = self.out1(bert_outputs[1])\n",
        "          # out1 = self.relu(out1)\n",
        "          # out1 = self.dropout(out1)\n",
        "          # logits = self.out2(out1)\n",
        "          return out1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNhLowlqQncj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "f50f84340a064210acba40d1e76a0ead",
            "b591d317588d4eba9ee2b91065ce5818",
            "631e291299d14cc9b2be93168cb5efc5",
            "dbe1bab8f2f2479b9593dc340229e679",
            "7064efaf864548c8804c09a6b61c6515",
            "df75cfecb4b94364b1b36bb9bf2dd9a0",
            "fa3b42a91dab4e148b7286b3125c7798",
            "d27274be05f7498898ddffac14a64a74",
            "01ae16ab60f941ceb37ea190155bf5cd",
            "ac743f4fb21042e294d93f4fb577557c",
            "84a91e0925e049d0ac04e700d7751905",
            "4bbf59aba72d40458baf8fa79e4064d9",
            "5221a967e8034f33b6c739554b7999c2",
            "6b67a5b728d147b5b02f940077ae584d",
            "c6cc9ce8144443999268a147f2312249",
            "1755d89fd712463b8595e5878b9cce9e",
            "8d36079de2984fad9c160bca1b48fe98",
            "1a7c4fbd142745569ac1480db6661daa",
            "28cb707c913b4fc5b90b91970f8ea8c9",
            "db3fa894a19047c997f3bf33987adda5",
            "c619123b55d74ae0a392634c7a757e2b",
            "001f239058aa4d859e7226a682fc65f0",
            "65cdfe2f55c04106bdb2cd5b1c1a6efb",
            "bbe66f41063144b0851119e536b87f6d"
          ]
        },
        "outputId": "530c8a43-e9a0-4fb3-c14c-467ee75a15d5"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model = CustomBERTModel().to(device)\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f50f84340a064210acba40d1e76a0ead",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01ae16ab60f941ceb37ea190155bf5cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d36079de2984fad9c160bca1b48fe98",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I60cUd8mbgX8"
      },
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, targets, max_len):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        self.max_len = max_len\n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "        x = self.data[index]\n",
        "        label = torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        return [x, label]\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9sYwWXdQ3IR"
      },
      "source": [
        "def encode_sentence(sentence, max_len):\n",
        "    return bert_tokenizer.batch_encode_plus(\n",
        "                        sentence,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_len,           # Pad & truncate all sentences.\n",
        "                        padding = 'max_length',\n",
        "                        truncation = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt'    # Return pytorch tensors.\n",
        "                   )\n",
        "train_dataset = MyDataset(train_data['input'].to_numpy(), train_data[0].to_numpy(), max_len[1])\n",
        "\n",
        "validation_dataset = MyDataset(test_data['input'].to_numpy()[:len(test_data['input'])//2], \n",
        "                               test_data[0].to_numpy()[:len(test_data['input'])//2], max_len[1])\n",
        "\n",
        "test_dataset = MyDataset(test_data['input'].to_numpy()[len(test_data['input'])//2:], \n",
        "                               test_data[0].to_numpy()[len(test_data['input'])//2:], max_len[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRzhogA9SHFL"
      },
      "source": [
        "bs = 16\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            shuffle = True,\n",
        "            # sampler = SequentialSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = bs # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            validation_dataset,  # The training samples.\n",
        "            sampler = SequentialSampler(validation_dataset), # Select batches sequentially\n",
        "            batch_size = bs # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,  # The training samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Sequentially\n",
        "            batch_size = bs # Trains with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajToVkJHJ345"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emPq2FgA1I06"
      },
      "source": [
        "# optimizer = AdamW([{'params': bert_model.bert.parameters(), 'weight_decay': 1e-1},\n",
        "#                    {'params': bert_model.out1.parameters(), 'lr': 1e-3},\n",
        "#                   #  {'params': bert_model.out1.parameters(), 'lr': 1e-3}\n",
        "#                    ],\n",
        "#                   lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "#                   eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
        "#                    )\n",
        "optimizer = AdamW(params = bert_model.parameters(), lr=1e-3)\n",
        "loss = nn.BCEWithLogitsLoss(reduction = 'none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma4uaKuB0K4m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a72fde-92b7-4596-a814-b4dd6e8482f8"
      },
      "source": [
        "epochs = 10\n",
        "MAX_LEN = 512\n",
        "for epoch_i in range(0, epochs):\n",
        "    train_loss = [0, 0]\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,} Loss {:>5,}.'.format(step, len(train_dataloader), train_loss[0]/train_loss[1]))\n",
        "        inputs = batch[0]\n",
        "        labels = batch[1]\n",
        "        inputs_encoded = encode_sentence(inputs, MAX_LEN)\n",
        "        for ele in inputs_encoded:\n",
        "            inputs_encoded[ele] = inputs_encoded[ele].to(device)\n",
        "        inputs_encoded['token_type_ids'] = None\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = bert_model(**inputs_encoded)\n",
        "        curr_batch_size = labels.size()[0]\n",
        "        curr_loss = loss(logits, labels)\n",
        "        curr_weights = torch.tensor(weights2).to(device)\n",
        "        curr_loss = (curr_loss).sum()\n",
        "        curr_loss.backward()\n",
        "        train_loss[0]+= curr_loss.data.cpu().item()\n",
        "        train_loss[1]+= curr_batch_size\n",
        "        optimizer.step()\n",
        "    print('Training Loss is : %f'%(train_loss[0]/train_loss[1]))\n",
        "    bert_model.eval()\n",
        "    val_loss = [0, 0]\n",
        "    for step, batch in enumerate(validation_dataloader):\n",
        "        inputs = batch[0]\n",
        "        labels = batch[1]\n",
        "        inputs_encoded = encode_sentence(inputs, MAX_LEN)\n",
        "        for ele in inputs_encoded:\n",
        "            inputs_encoded[ele] = inputs_encoded[ele].to(device)\n",
        "        inputs_encoded['token_type_ids'] = None\n",
        "        labels = labels.to(device)\n",
        "        with torch.no_grad():\n",
        "            logits = bert_model(**inputs_encoded)\n",
        "            curr_batch_size = labels.size()[0]\n",
        "            curr_loss = loss(logits, labels)\n",
        "            curr_weights = torch.tensor(weights2).to(device)\n",
        "            curr_loss = (curr_loss * curr_weights).sum()\n",
        "            val_loss[0]+= curr_loss.data.cpu().item()\n",
        "            val_loss[1]+= curr_batch_size\n",
        "    bert_model.train()\n",
        "    print('Validation Loss is : %f'%(val_loss[0]/val_loss[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    892 Loss 2.5385136914253237.\n",
            "  Batch   200  of    892 Loss 2.4822037279605866.\n",
            "  Batch   300  of    892 Loss 2.458810783624649.\n",
            "  Batch   400  of    892 Loss 2.444874472618103.\n",
            "  Batch   500  of    892 Loss 2.4343961281776427.\n",
            "  Batch   600  of    892 Loss 2.4266151334842045.\n",
            "  Batch   700  of    892 Loss 2.4213785081250325.\n",
            "  Batch   800  of    892 Loss 2.409520927518606.\n",
            "Training Loss is : 2.403410\n",
            "Validation Loss is : 3.334296\n",
            "  Batch   100  of    892 Loss 2.306348143815994.\n",
            "  Batch   200  of    892 Loss 2.3154092717170713.\n",
            "  Batch   300  of    892 Loss 2.3119807402292887.\n",
            "  Batch   400  of    892 Loss 2.3101575070619584.\n",
            "  Batch   500  of    892 Loss 2.31069926071167.\n",
            "  Batch   600  of    892 Loss 2.310451078414917.\n",
            "  Batch   700  of    892 Loss 2.310920545033046.\n",
            "  Batch   800  of    892 Loss 2.3153799030184747.\n",
            "Training Loss is : 2.312337\n",
            "Validation Loss is : 3.381605\n",
            "  Batch   100  of    892 Loss 2.2401517045497896.\n",
            "  Batch   200  of    892 Loss 2.235116106271744.\n",
            "  Batch   300  of    892 Loss 2.248255887031555.\n",
            "  Batch   400  of    892 Loss 2.252315573990345.\n",
            "  Batch   500  of    892 Loss 2.270100620985031.\n",
            "  Batch   600  of    892 Loss 2.2700251468022663.\n",
            "  Batch   700  of    892 Loss 2.2724622404575348.\n",
            "  Batch   800  of    892 Loss 2.2733153094351293.\n",
            "Training Loss is : 2.276525\n",
            "Validation Loss is : 3.198147\n",
            "  Batch   100  of    892 Loss 2.2527354300022124.\n",
            "  Batch   200  of    892 Loss 2.270138837099075.\n",
            "  Batch   300  of    892 Loss 2.262724444468816.\n",
            "  Batch   400  of    892 Loss 2.265133059322834.\n",
            "  Batch   500  of    892 Loss 2.266151212930679.\n",
            "  Batch   600  of    892 Loss 2.2727883891264598.\n",
            "  Batch   700  of    892 Loss 2.266012897150857.\n",
            "  Batch   800  of    892 Loss 2.261242409050465.\n",
            "Training Loss is : 2.261877\n",
            "Validation Loss is : 3.226911\n",
            "  Batch   100  of    892 Loss 2.1713201713562014.\n",
            "  Batch   200  of    892 Loss 2.208662962317467.\n",
            "  Batch   300  of    892 Loss 2.2304719030857085.\n",
            "  Batch   400  of    892 Loss 2.234759067595005.\n",
            "  Batch   500  of    892 Loss 2.2360305197238923.\n",
            "  Batch   600  of    892 Loss 2.230571461121241.\n",
            "  Batch   700  of    892 Loss 2.23834296975817.\n",
            "  Batch   800  of    892 Loss 2.245616295784712.\n",
            "Training Loss is : 2.246253\n",
            "Validation Loss is : 3.327917\n",
            "  Batch   100  of    892 Loss 2.2855451560020446.\n",
            "  Batch   200  of    892 Loss 2.2524180245399474.\n",
            "  Batch   300  of    892 Loss 2.248693743546804.\n",
            "  Batch   400  of    892 Loss 2.230102147758007.\n",
            "  Batch   500  of    892 Loss 2.2344830105304716.\n",
            "  Batch   600  of    892 Loss 2.2312537383039794.\n",
            "  Batch   700  of    892 Loss 2.228676033105169.\n",
            "  Batch   800  of    892 Loss 2.2303128100186584.\n",
            "Training Loss is : 2.230653\n",
            "Validation Loss is : 3.165343\n",
            "  Batch   100  of    892 Loss 2.2820265781879425.\n",
            "  Batch   200  of    892 Loss 2.262707659602165.\n",
            "  Batch   300  of    892 Loss 2.237993673880895.\n",
            "  Batch   400  of    892 Loss 2.240764134526253.\n",
            "  Batch   500  of    892 Loss 2.234879307985306.\n",
            "  Batch   600  of    892 Loss 2.2343436525265377.\n",
            "  Batch   700  of    892 Loss 2.237342983654567.\n",
            "  Batch   800  of    892 Loss 2.233371640890837.\n",
            "Training Loss is : 2.233230\n",
            "Validation Loss is : 3.262914\n",
            "  Batch   100  of    892 Loss 2.2041100060939787.\n",
            "  Batch   200  of    892 Loss 2.2282501608133316.\n",
            "  Batch   300  of    892 Loss 2.219964028994242.\n",
            "  Batch   400  of    892 Loss 2.2232131260633468.\n",
            "  Batch   500  of    892 Loss 2.223660536289215.\n",
            "  Batch   600  of    892 Loss 2.224050139983495.\n",
            "  Batch   700  of    892 Loss 2.2230526217392512.\n",
            "  Batch   800  of    892 Loss 2.227794777005911.\n",
            "Training Loss is : 2.226927\n",
            "Validation Loss is : 3.174595\n",
            "  Batch   100  of    892 Loss 2.2339633715152742.\n",
            "  Batch   200  of    892 Loss 2.234831086397171.\n",
            "  Batch   300  of    892 Loss 2.2245263417561847.\n",
            "  Batch   400  of    892 Loss 2.229762053489685.\n",
            "  Batch   500  of    892 Loss 2.2100319981575014.\n",
            "  Batch   600  of    892 Loss 2.2257542518774667.\n",
            "  Batch   700  of    892 Loss 2.2239514897550854.\n",
            "  Batch   800  of    892 Loss 2.221021971553564.\n",
            "Training Loss is : 2.224117\n",
            "Validation Loss is : 3.133136\n",
            "  Batch   100  of    892 Loss 2.183386127948761.\n",
            "  Batch   200  of    892 Loss 2.16531190097332.\n",
            "  Batch   300  of    892 Loss 2.186851795911789.\n",
            "  Batch   400  of    892 Loss 2.1911096087098123.\n",
            "  Batch   500  of    892 Loss 2.1998919081687927.\n",
            "  Batch   600  of    892 Loss 2.2051876107851665.\n",
            "  Batch   700  of    892 Loss 2.203386980124882.\n",
            "  Batch   800  of    892 Loss 2.206973843574524.\n",
            "Training Loss is : 2.211077\n",
            "Validation Loss is : 3.079933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKnmVZi_KQE0"
      },
      "source": [
        "torch.save(bert_model.state_dict(), './bert-model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Niuuu9R2Rl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5904381-66bb-4821-c6cf-4435ee3e38be"
      },
      "source": [
        "bert = CustomBERTModel().to(device)\n",
        "bert.load_state_dict(torch.load('nlp/bert-model-base.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDhjF9FR6mD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f06f00ac-2ea8-47cb-9554-405d66e9b340"
      },
      "source": [
        "err_label = []\n",
        "err_logits = []\n",
        "bert_model.eval()\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "  input = batch[0]\n",
        "  labels = batch[1]\n",
        "  inputs_encoded = encode_sentence(input, 512)\n",
        "  curr_loss = 0\n",
        "  total_batch_size = 0\n",
        "  for ele in inputs_encoded:\n",
        "      inputs_encoded[ele] = inputs_encoded[ele].to(device)\n",
        "  labels = labels.to(device)\n",
        "  with torch.no_grad():\n",
        "    logits = bert_model(**inputs_encoded)\n",
        "    logits_to_labels = torch.sigmoid(logits)\n",
        "  err_label.extend(labels.data.cpu().numpy())\n",
        "  err_logits.extend(logits_to_labels.data.cpu().numpy())\n",
        "  total_batch_size += labels.size()[0]\n",
        "err_logits = np.array(err_logits)\n",
        "err_predictions = np.array(err_logits>0.5, dtype = np.int)\n",
        "labels = np.array(err_label, dtype=np.int)\n",
        "print(f1_score(labels, err_predictions, average='micro'))\n",
        "print(accuracy_score(labels, err_predictions))\n",
        "print(classification_report(labels, err_predictions, target_names=err_categories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5367065733002033\n",
            "0.5028026905829597\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CO       0.60      0.90      0.72       908\n",
            "          GM       0.82      0.13      0.23       527\n",
            "          LX       0.88      0.21      0.34       760\n",
            "          OT       0.72      0.34      0.46       418\n",
            "\n",
            "   micro avg       0.65      0.45      0.54      2613\n",
            "   macro avg       0.76      0.40      0.44      2613\n",
            "weighted avg       0.75      0.45      0.47      2613\n",
            " samples avg       0.55      0.54      0.54      2613\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkHHyqmBsfSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0515213-6ba8-4a3a-c536-af87e134cb56"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Nov 10 04:07:45 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    24W /  75W |   7551MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}